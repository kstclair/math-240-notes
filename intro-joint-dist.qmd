# Introduction to joint distributions  {#sec-intro-joint-dist}

We will revisit chapters 4 and 6 of @dobrow to describe joint distributions that can explain/model bivariate relationships between two (or more) random variables. We jump around from chapter 4 (discrete) and chapter 6 (continuous) to cover this topic.

Make sure to review our [week 7 schedule](https://docs.google.com/spreadsheets/d/10AP55TSo0bgqklDCOioCiiBYEZAyhIytcNe8qmd2nu8/edit?usp=sharing).



## Day 18 {.unnumbered}

- What to read: Read sections 4.3, 6.6, review Appendix D if you need multivariate integration review

- Learning objectives: These sections will help you
  - understand what a joint distribution (pdf/pmf) is
  - understand what a marginal distribution (pdf/pmf) is
  - compute a marginal pdf/pmf from a joint pdf/pmf
  - compute probabilities from a joint pdf/pmf
  
- After reading, take reading [quiz 14](https://forms.gle/XKWqF5TZ1qVWDscE9)

  
### Sections 4.3 and 6.6 {.unnumbered}

Key terminology to know:

  - [ ] joint pmf (two discrete RV) and joint pdf (two continuous RV)
  - [ ] marginal distribution (pmf or pdf)
  - [ ] continuous joint cdf 
  - [ ] continuous bivariate pdf

Comments: 

- You can skip over the expectations on page 139 (equation 4.3) and 255 for now -  we'll cover this idea Friday.
- Computing probabilities from a joint pdf requires calculation of a double integral. As in single random variable integration, setting up the problem with the correct limits of integration is the key step here. **Draw a picture** of the event (region) that you want to find the probability of and **intersect** it with the support set for your pdf. It is this region that determines your limits!
- Make sure you review Appendix D if you are rusty with double integrals.




## Day 19 {.unnumbered}

- What to read: Read section 6.7, review independence from 4.4 

- Learning objectives: These sections will help you
  - understand what independence for two (or more) RV means
  - how to *prove* independence OR how to *use* independence to construct joint pdf/pmf
  
- After reading, take reading [quiz 15](https://forms.gle/UvGofRr38VkZCCtf7)

  
### Sections 4.4 and 6.7 {.unnumbered}

Key terminology to know:

  - [ ] independent continuous RV 
  - [ ] independent discrete RV 

Comments: 

- You can skim 6.7.1 on the accept-reject method.
- The assumption of independence between two RV makes the derivation of the joint pdf/pmf very easy since it is just the product of the two (marginal) pdf/pmf. 



## Day 20 {.unnumbered}

- What to read: Read expectation definitions on pages 139 and 255 and sections 4.7, 6.8, 9.6


- Learning objectives: These sections will help you
  - compute the expected value of a function of two discrete or continuous RV
  - understand how covariance and correlation are used to measure the *linear* dependence between two RV
  - compute the covariance and correlation between two RV
  - compute the variance of a linear combination of two RV when they are not independent
  - see an example of a bivariate distribution with a parameter that measures correlation
  
- After reading, take reading [quiz 16](https://forms.gle/b5vx8Ezd2b5SB2Jz9)

  
### Sections 4.7, 6.8, and 9.6 and pages 139, 255 {.unnumbered}

Key terminology to know:

  - [ ] expected value of a function of two RV
  - [ ] covariance
  - [ ] correlation
  - [ ] general formula for the variance of a sum of random variables
  - [ ] bivariate normal model

Comments: 

- Take a look at section 9.6 through page 391 to see an example of a joint pdf with a parameter that measures correlation. 