[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "math-240-notes",
    "section": "",
    "text": "Math 240 Probability\nThis is a reading guide resource for students in my Math 240 Probability class taught at Carleton College (Northfield, MN). Our textbook is Wagaman (2021). You can find this book online in our library.\n\n\n\n\nWagaman, & Dobrow, A. S. 2021. Probability: With Applications and r. 2nd ed. Wiley.",
    "crumbs": [
      "Math 240 Probability"
    ]
  },
  {
    "objectID": "first-principles.html",
    "href": "first-principles.html",
    "title": "1  First principles of probability",
    "section": "",
    "text": "Day 1",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>First principles of probability</span>"
    ]
  },
  {
    "objectID": "first-principles.html#day-1",
    "href": "first-principles.html#day-1",
    "title": "1  First principles of probability",
    "section": "",
    "text": "What to read: Read sections 1.1, 1.2, 1.3, 1.4, and 1.8 to see the generalization of property #3.\nLearning objectives: These sections will help you\n\ndefine basic probability and set theory terminology\ndefine fundamental properties of probability\n\n\n\nSection 1.1\nKey terminology to know:\n\nSample space \\(\\Omega\\)\nOutcome \\(\\omega\\): this can also be called an element\nEvent \\(A\\), \\(B\\), …\n\nComments:\nThe sample space for a random experiment is the list of all possible outcomes. To define a sample space, start by thinking about how to define a couple individual outcomes and then generalize this to all outcomes. If there are a large or infinite number of outcomes, then you can use a “…” to show that a pattern will continue (like Examples 1.3 and 1.4).\nThere may not be a unique way to define a sample space and outcomes for a random experiment. For example, one may chose to define the sample space for Example 1.3 as just the number of votes for Yolanda \\[\\Omega = \\{ 0, 1, 2, \\dotsc, 999, 1000\\}\\]. But all the outcomes in a sample space must define unique possibilities for a random experiment (i.e. they are mutually exclusive, section 1.4).\n“Complex” random experiments are often composed of simpler experiments. Example 1.2 is an example of this as we define one outcome for two dice rolls as the joint outcome of two individual die rolls. Similar for the sample space for three coin flips. In scenarios where the individual simpler experiments have equally likely outcomes, the outcomes in the more complex sample space (e.g. two dice rolls, three coin flips) are also equally likely outcomes.\n\n\nSection 1.2-1.3\nKey ideas to know:\n\nrelative frequency interpretation of probability\nprobability function and its essential properties\n\nComments:\nMake sure you can put the probability function properties into words: (1) means probabilities can’t be negative, (2) means something in the sample space has to happen with probability 1 and (3) means the probability of an event is just the sum of the probabilities of outcomes that make up that event.\n\n\nSection 1.4 + 1.8\nKey set theory ideas to know\n\ncomplement \\(A^c\\) (not \\(A\\))\nunion \\(A \\cup B\\) (at least one \\(A\\) or \\(B\\) or both)\nintersection \\(A \\cap B = AB\\) (both \\(A\\) and \\(B\\))\n\\((AB)^c = A^c \\cup B^c\\) (at most one)\n\\((A \\cup B)^c = A^cB^c\\) (neither)\n\\(AB^c\\) (\\(A\\) but not \\(B\\))\nsubset \\(\\subseteq\\)\nmutually exclusive/disjoint events\nVenn diagram\nempty set \\(\\emptyset\\)\n\nComments:\nThe first six ideas create a new event out of one or more events (think addition, subtraction, etc). Subset, mutually exclusive and Venn diagrams tells us relational information about events (think less than, etc). The empty set is a set that has no outcomes (think zero).\nKey probability properties to know\n\nAddition rule for mutually exclusive events (only add probability of events when they are mutually exclusive)\nGeneral addition rule (events do not need to be mutually exclusive)\nComplement rule\n\nComments:\nThe addition rule properties are used to find the probability of a union of two or more events. When events are mutually exclusive, we just add the individual event probabilities. Make sure that you assess whether events are mutually exclusive before simply adding their probabilities.\nWhen events are not mutually exclusive, you start by adding event probabilities but then you need to subtract out the probability of the overlap (intersection) between events. The inclusion/exclusion rule is an extension of property (3) (eq. 1.3).\nThe complement rule along with the addition rule is useful for computing the probability of neither \\(A\\) nor \\(B\\): \\[\nP(A^c B^c) = 1 - P(A \\cap B)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>First principles of probability</span>"
    ]
  },
  {
    "objectID": "first-principles.html#day-2",
    "href": "first-principles.html#day-2",
    "title": "1  First principles of probability",
    "section": "Day 2",
    "text": "Day 2\n\nWhat to read: Read sections 1.5 and 1.6\nLearning objectives: These sections will help you\n\nuse the multiplication principle to count the number of outcomes in a sample space or event\ncompute event probabilities using counting when outcomes are equally likely\ndefine and count permutations\n\nAfter reading, take reading quiz 1\n\n\nSection 1.5\nKey idea to know:\n\nequally like outcomes\n\nComments:\nOur definition of the probability function Section 1.3 means that the probability of any event \\(A\\) is equal to the number of outcomes in \\(A\\) divided by the total number of outcomes when all outcomes are equally likely.\n\n\nSection 1.6\nKey ideas to know:\n\nmultiplication principle\npermutation\ncounting the number of permutations of \\(n\\) unique/distinct objects\ncounting the number of permutations of size \\(k\\) from \\(n\\) unique/distinct objects\nsampling with vs without replacement\n\nComments:\nThe outcomes counted by the multiplication principle describe a specific ordering, or arrangement, of a random experiment. For example 1.13, the outcomes in the sample space are found by fixing the exam (eg exams 1-4) and randomly assigning one of five grades to each exam. There are \\(5\\times5\\times5\\times5 = 5^4\\) such outcomes in the sample space. The complement of the event of interest is getting no A’s and we must describe outcomes in this set the same way that we described them in the sample space (eg assigning one of four non-A grades to each exam). There are \\(4^4\\) such ways to assign a non-A grade to each exam.\nPermutations are always ordered arrangements of unique/distinct objects or individual outcomes.\nExample 1.14 shows a common technique in counting problems. One outcome describes a specific (unique) arrangement of 15 books (eg positions 1-5 are top shelf, 6-10 middle, and 11-15 bottom). There are 15! such arrangements in the sample space. The event of interest, all math books on the bottom, uses both permutation counting and the multiplication principle. Permutations counts the number of ways to arrange math books (5!) and novels (10!). Each unique arrangement of math books can be combined with each unique arrangement of novels. Hence the multiplication principle is used to count the number of ways to get 10 novels on the top and middle shelves and 5 math books on the bottom: \\(10! \\times 5!\\).\nOne twist to problem 1.14: suppose the event of interest was simply that the 5 math books were on the same shelf (ie they could be on the top, middle or bottom shelves). Each of these three options, \\(A_{top}, A_{middle}, A_{bottom}\\) for math book placement has \\(10! \\times 5!\\) ways to arrange the books and each of these shelf positions \\(A_{i}\\) is mutually exclusive. Hence the probability that the 5 math books are on the same shelf is found using the addition rule for mutually exclusive events: \\[\nP(A_{top} \\cup A_{middle} \\cup A_{bottom}) = P(A_{top}) + P(A_{middle}) +  P(A_{bottom}) = 3 \\times \\dfrac{10! \\times 5!}{15!}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>First principles of probability</span>"
    ]
  },
  {
    "objectID": "first-principles.html#day-3",
    "href": "first-principles.html#day-3",
    "title": "1  First principles of probability",
    "section": "Day 3",
    "text": "Day 3\n\nWhat to read: Read sections 1.7\nLearning objectives: These sections will help you\n\ndefine and count combinations using the binomial coefficient\nuse the binomial coefficient to count permutations of two types of objects (a binary sequence)\ndistinguish between a permutation and a combination\n\nAfter reading, take reading quiz 2\n\n\nSection 1.7\nKey ideas to know:\n\ncombination\ncorrespondence between a binary sequence/list and an unordered subset/sample of size \\(k\\) from \\(n\\) unique objects\nbinomial coefficient\n\nComments:\nWe will be considering counting problems where outcomes are either ordered and unordered. Make sure that your strategy for solving a problem is consistent when counting sample space and event outcomes (eg don’t use an ordered strategy for one and an unordered strategy for the other).\nWhile you need to describe outcomes in an event and sample space of interest in the same manner, you don’t need to use the same counting method to count outcomes in each. e.g. Example 1.26 uses the multiplication principle to count all possible ways to flip a coin 20 times while the binomial coefficient is used to count how many of these outcomes contain example 10 H and 10 T.\nThe binomial coefficient, which counts both the number of unordered subsets of unique objects and the number of binary sequences, can be generlized to a multinomial coefficient. Example 1.15(ii) involves picking 4 subsets of 13 cards from a deck of 52: \\(\\frac{52!}{13!13!13!13!}\\). Example 1.27(ii) also uses a multinomial coefficient in the numerator: \\(\\frac{20!}{4!5!3!8!}\\) counts the number of ways to arrange 4 As, 5 Gs, 3 Ts, and 8 Cs.\nDon’t worry about the binomial theorem (and its proof) for now.\n\n\n\n\nWagaman, & Dobrow, A. S. 2021. Probability: With Applications and r. 2nd ed. Wiley.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>First principles of probability</span>"
    ]
  },
  {
    "objectID": "thinking-conditionally.html",
    "href": "thinking-conditionally.html",
    "title": "2  Thinking conditionally",
    "section": "",
    "text": "Day 4",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Thinking conditionally</span>"
    ]
  },
  {
    "objectID": "thinking-conditionally.html#day-4",
    "href": "thinking-conditionally.html#day-4",
    "title": "2  Thinking conditionally",
    "section": "",
    "text": "What to read: Read sections 2.1, 2.2, 2.3\nLearning objectives: These sections will help you\n\nconceptualize and compute a conditional probability\nuse the general multiplication rule to compute the probabilities of intersections\nuse tree diagrams to organize conditional information and compute probabilities\n\nAfter reading, take reading quiz 3\n\n\nSection 2.1 and 2.2\nKey terminology to know:\n\nconditional probability function and its essential properties\n\nComments:\nDon’t get bogged down in the notation choice used to define a conditional probability, \\(P(A \\mid B)\\). The big idea is that to compute a conditional probability we compute the ratio of the intersection probability (chance that both events occur) relative to the probability of the event we are conditioning on (ie the event that has occurred).\nDon’t worry about the simulation code in example 2.3.\nThe conceptual idea in 2.2 is most important, that a conditional probability function \\(P( \\cdot \\mid B)\\) should have the same properties as an unconditional probability \\(P(\\cdot)\\). The only difference is that the sample space for the conditional probability is restricted to only outcomes that agree with the conditional information.\n\n\nSection 2.3\nKey terminology to know:\n\ngeneral multiplication rule for two or more events\ntree diagram\n\nComments:\nTree diagrams are a useful visual tool for organizing information that is conditional or sequential in nature. Venn diagrams are not useful for organizing such information.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Thinking conditionally</span>"
    ]
  },
  {
    "objectID": "thinking-conditionally.html#day-5",
    "href": "thinking-conditionally.html#day-5",
    "title": "2  Thinking conditionally",
    "section": "Day 5",
    "text": "Day 5\n\nWhat to read: Read sections 2.4 and 2.5\nLearning objectives: These sections will help you\n\nuse the law of total probability to compute an unconditional probability from conditional information\nuse Bayes rule to compute a “flipped/inverted” conditional probability\n\nAfter reading, take reading quiz 4\n\n\nSection 2.4\nKey terminology to know:\n\nsample space partition\nlaw of total probability (LoTP)\n\nComments:\nRecognize that the LoTP uses both the multiplication rule (to compute intersections) and the addition rule for mutually exclusive events.\n\n\nSection 2.5\nKey terminology to know:\n\nBayes formula/rule\ntree diagram\n\nComments:\nBayes formula is useful when we want to flip the direction of a conditional probability, eg. we want \\(P(B \\mid A)\\) but we are given \\(P(A \\mid B)\\) along with unconditional info about \\(B\\). But the formula didn’t appear from nothing, it is based on the original definition of a conditional probability from 2.1: the numerator is the multiplication rule and the denominator is the LoTP.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Thinking conditionally</span>"
    ]
  },
  {
    "objectID": "thinking-conditionally.html#day-6",
    "href": "thinking-conditionally.html#day-6",
    "title": "2  Thinking conditionally",
    "section": "Day 6",
    "text": "Day 6\n\nWhat to read: Read sections 2.6\nLearning objectives: These sections will help you\n\ndetermine whether events are independent or dependent\ncompute intersection probabilities if events are independent\n\nAfter reading, take reading quiz 5\n\n\nSection 2.6\nKey terminology to know:\n\nindependent and dependent events\nmutual independence\nmultiplication rule for independent events\n\nComments:\nIndependence is proved (or disproved) by thinking conditionally: if the occurrence of \\(B\\) doesn’t affect the probability of \\(A\\), then these events are independent.\nIf we know events are independent, then we can multiply unconditional probabilities to compute intersections. A common error is that I see is when the multiplication rule for independent events is used without first checking the essential assumption of independence.\nDon’t worry about \\(A\\) before \\(B\\) results (ie they are interesting but not a general rule you need to know).\n\n\n\n\nWagaman, & Dobrow, A. S. 2021. Probability: With Applications and r. 2nd ed. Wiley.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Thinking conditionally</span>"
    ]
  },
  {
    "objectID": "intro-discrete-rv.html",
    "href": "intro-discrete-rv.html",
    "title": "3  Introduction to discrete random variables",
    "section": "",
    "text": "Day 7",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to discrete random variables</span>"
    ]
  },
  {
    "objectID": "intro-discrete-rv.html#day-7",
    "href": "intro-discrete-rv.html#day-7",
    "title": "3  Introduction to discrete random variables",
    "section": "",
    "text": "What to read: Read sections 3.1, 3.2, 3.3, 3.4, plus the pmf definition on page 126\nLearning objectives: These sections will help you\n\nunderstand what a “random variable” (RV) is\ndefine a probability mass function and support set for a discrete RV\nunderstand whether discrete RV are independent\nget familiar with some common discrete RV types (uniform, Bernoulli, binomial, Poisson)\n\nAfter reading, take reading quiz 6\n\n\nSection 3.1 and page 126\nKey terminology to know:\n\nrandom variable\ndiscrete random variable\nprobability mass function (pmf) of a RV\nthe (support) set \\(S\\) of a RV\nuniform RV (know shorthand notation, pmf and support set)\n\nComments:\nPay special attention to the notation used for random variables (RV). Uppercase letters (typically at the end of the English alphabet) are used to denote the RV (which is random and doesn’t have a fixed value) while lower case are used to denote a fixed numeric value (which is fixed even though there may not be a value specified).\nThe “distribution” of a random variable describes the probability structure of the RV, so think pmf if you are asked to describe a distribution. (ie what values of the RV are most likely, which ones are less likely, etc) You can also describe a distribution of a RV by name if it has a common pmf (eg “The distribution of \\(X\\) is discrete uniform.”)\nThe subsection “Random variables as function” explains how a RV \\(X(\\cdot)\\) takes in one or more outcomes \\(\\omega\\) from the sample space of an experiment and outputs a numeric value. This is our formal definition of a RV but we typically won’t be using the \\(X(\\omega)\\) notation for a RV. Instead we will just refer to RV as \\(X\\), \\(Y\\), etc. But keep this underlying connection with the sample space in mind as the term progresses (especially for discrete RV).\nThe uniform random variable box on page 96 is an example of a probability mass function (pmf) and support set \\(S\\). Even though pmf aren’t formally defined until ch. 4, I find it useful to use that language at the start of discrete RV discussions.\n\n\nSection 3.2\nKey terminology to know:\n\nindependent discrete random variables\n\nComments:\nWe can use either Equations 3.1 or 3.2 to define two independent discrete RV. The general definition of independent random variables on page 98 extends beyond discrete RV to continuous RV (which we will cover soon). Skim this idea but our main focus right now is discrete RV.\n\n\nSection 3.3 and 3.4\nKey terminology to know:\n\nBernoulli RV (know shorthand notation, what it counts, pmf and support set)\nIndependent and identically distributed (i.i.d.)\nBinomial RV (know shorthand notation, what it counts, pmf and support set)\n\nComments:\nBernoulli and binomial RV are extremely common types of RV so make sure to carefully review these sections.\nYour book describes a binomial RV as the sum of an [i.i.d.] Bernoulli “sequence” of length \\(n\\). Another common way to describe this is the use the phrasing “trials” instead of “sequence”: a binomial RV is the sum of \\(n\\) i.i.d. Bernoulli trials.\nThe R code on pages 102 and 104 will be talked about on day 8.\nSkim Example 3.14 but we will focus on solving problems involving two RV later on this term.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to discrete random variables</span>"
    ]
  },
  {
    "objectID": "intro-discrete-rv.html#day-8",
    "href": "intro-discrete-rv.html#day-8",
    "title": "3  Introduction to discrete random variables",
    "section": "Day 8",
    "text": "Day 8\n\nWhat to read: Read sections 3.5\nLearning objectives: These sections will help you\n\nget familiar with the Poisson distribution\nreview or get introduced to infinite series\n\nAfter reading, take reading quiz 7\n\n\nSection 3.5\nKey terminology to know:\n\nPoisson RV (know shorthand notation, what it counts, pmf and support set)\n\nComments:\nA Poisson RV is another RV that counts “things”, make sure you can distinguish settings where we should be modeling a count RV as a Poisson RV vs. a binomial RV (vs. something else).\nSeries are a Calc BC or Math 210 topic that not all of you have seen. If you haven’t had prior exposure to these ideas please stop by drop-in hours (or make an appointment) if you have questions! Appendix C at the end of your book reviews some useful math/calc facts, including some common series. You can use these facts without deriving them from scratch.\nSkim 3.5.1 and 3.5.2. Time permitting, I’ll cover the proof connecting the binomial and Poisson distributions from 3.5.2 class (it’s fun!) but it isn’t essential course material.\n\n\n\n\nWagaman, & Dobrow, A. S. 2021. Probability: With Applications and r. 2nd ed. Wiley.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to discrete random variables</span>"
    ]
  },
  {
    "objectID": "more-discrete-rv.html",
    "href": "more-discrete-rv.html",
    "title": "4  More with discrete random variables",
    "section": "",
    "text": "Day 10",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>More with discrete random variables</span>"
    ]
  },
  {
    "objectID": "more-discrete-rv.html#day-10",
    "href": "more-discrete-rv.html#day-10",
    "title": "4  More with discrete random variables",
    "section": "",
    "text": "What to read: Read sections 4.1, 4.2, 4.4, 4.5 but review the comments below on what to skim/skip.\nLearning objectives: These sections will help you\n\nconceptualize and compute the expected value of a discrete random variable and a function of a discrete random variable\nconceptualize and compute the expected value of a linear function of two or more discrete random variable\nconceptualize and compute the expected value of a product of two independent discrete random variable\n\nAfter reading, take reading quiz 8\n\n\nSection 4.1 and 4.2\nKey terminology to know:\n\nExpectation, or expected value, of a random variable, denoted \\(E(X)\\) where \\(X\\) is the random variable\nA function of a random variable, often denoted \\(g(X)\\), and its expectation\nA linear function of a random variable, denoted \\(aX+b\\), and its expectation\n\nComments:\n\nWe will skip 4.3 for now and we’ll formally cover joint pmf in a couple weeks.\nExamples 4.3, 4.4, 4.8 use Series facts shown in Appendix C. Be comfortable using these facts to compute expectations.\nThe expectation of a linear function of a random variable is an extremely useful fact so make sure you spend some time absorbing it. For example, suppose \\(X\\) counts the number of red lights in 5 days (ie it is Binomial). We might care more about \\(X/5\\), which is the proportion of read lights in a week. If we know \\(E(X)\\), the average number of red lights in a week, then we can easily compute \\(E(X/5)\\) using this rule.\nThe R code shows simulation examples that can be used to approximate an expected value. We won’t be doing simulations this term but feel free to run the code if you want to learn how to do this for selected examples.\n\n\n\nSection 4.4 and 4.5\nKey terminology to know:\n\nExpectation of the product of two independent random variables\nExpectation of a linear combination of two or more random variables\n\nComments:\n\nFor section 4.4, focus on the expectation rules for indep. RV in Equations 4.4 and 4.5. We will formally define and work with joint pmf later this term.\nSkim Section 4.4.1. We will prove that sums of independent Poisson RVs is Poisson using a different method.\nFor section 4.5, focus on the linearity result at the start of the section but don’t worry about the proof (for now)\nThe expectation of a linear function of two or more random variable is an extremely useful fact so make sure you spend some time absorbing it.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>More with discrete random variables</span>"
    ]
  },
  {
    "objectID": "more-discrete-rv.html#day-11",
    "href": "more-discrete-rv.html#day-11",
    "title": "4  More with discrete random variables",
    "section": "Day 11",
    "text": "Day 11\n\nWhat to read: Read sections 4.6, 5.2\nLearning objectives: These sections will help you\n\nconceptualize and compute the variance and standard deviation of a discrete random variable\ncompute the variance and standard deviation of a linear function of a discrete random variable\ncompute the variance and standard deviation of a linear function of two independent discrete random variables\nunderstand how moments of a random variable can be computed via the moment generating function\nunderstand how to use moment generating functions to determine the distribution of a function of one or more random variables\n\nAfter reading, take reading quiz 9\n\n\nSection 4.6\nKey terminology to know:\n\nvariance\nstandard deviation\n\nComments:\n\nEquation 4.10 will be the typical way we compute variance/standard deviation since it is less mathematically intensive to compute compared to the expected value used to define it.\nExample 4.24 use Series facts shown in Appendix C.\n\n\n\nSection 5.2\nKey terminology to know:\n\nthe \\(k\\)th moments of a random variable\nmoment generating function (mgf)\n\nComments:\n\nWe jump ahead a bit to cover moment generating functions (mgf) which can be used to find expectations of the form \\(E(X^k)\\) (the \\(k\\)th moment).\nAn extremely useful fact about mgf’s is that they uniquely identify a random variable, eg if two random variables have the same mgf then they have the same distribution. This combined with the properties described on pages 195-6 make mgf’s a very useful tool for determining the distribution of linear combinations of one or more random variables.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>More with discrete random variables</span>"
    ]
  },
  {
    "objectID": "more-discrete-rv.html#day-12",
    "href": "more-discrete-rv.html#day-12",
    "title": "4  More with discrete random variables",
    "section": "Day 12",
    "text": "Day 12\n\nWhat to read: Read sections 5.1, 5.3, 5.4\nLearning objectives: These sections will help you\n\nget familiar with a few more common discrete RV types (geometric, negative binomial, and hypergeometric)\n\nAfter reading, take reading quiz 10\n\n\nSections 5.1, 5.3, 5.4\nKey terminology to know:\n\ngeometric RV (know shorthand notation, pmf and support set)\nmemorylessness of the geometric distribution\nnegative binomial RV (know shorthand notation, pmf and support set)\nhypergeometric RV (know shorthand notation, pmf and support set)\n\nComments:\n\nskim 5.1.2\nTake care to understand what the geometric and negative binomial random variables count. While the Binomial counts the number of “successes” in a fixed number of trials, the geometric/negative binomail fix the number of successes while the number of trials that it takes to get those successes is random.\nSome probability books or online sources define geometric and negative binomial random variables as the number failures until some fixed number of successes. Eg. if \\(X\\) is the number of trials until the 1st success, then \\(Y = X-1\\) is the number of failures until the 1st success. We will stick with the number of trials definition in this course.\nA hypergeometric random variable is similar in spirit as the binomial, but the hypergeometric counts the number of successes in a fixed sample size taken without replacement from a group of unique individuals. A binomial random variable is similar but it assumes with replacement, or independent sampling draw-to-draw.\n\n\n\n\n\nWagaman, & Dobrow, A. S. 2021. Probability: With Applications and r. 2nd ed. Wiley.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>More with discrete random variables</span>"
    ]
  },
  {
    "objectID": "intro-continuous-rv.html",
    "href": "intro-continuous-rv.html",
    "title": "5  Introduction to continuous random variables",
    "section": "",
    "text": "Day 13",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to continuous random variables</span>"
    ]
  },
  {
    "objectID": "intro-continuous-rv.html#day-13",
    "href": "intro-continuous-rv.html#day-13",
    "title": "5  Introduction to continuous random variables",
    "section": "",
    "text": "What to read: Read intro to ch. 6, sections 6.1, 6.2, 6.4, 7.1.3\nLearning objectives: These sections will help you\n\nunderstand what a continuous random variable is\nuse a probability mass function (pdf) to compute probabilities for events involving a continuous RV\nuse a cumulative distribution function (cdf) to compute probabilities for events involving a continuous RV\nunderstand how to get a pdf from a cdf and vice versa\ncompute quantiles for a continuous distribution\nget familiar with a (continuous) uniform RV\n\nAfter reading, take reading quiz 11\n\n\nSection 6.1\nKey terminology to know:\n\ncontinuous random variable\nprobability density function (pdf) of a continuous RV\n\nComments:\n\nPay particular attention to the comment box on page 230. I am very particular when asking for pdf (or cdf) functions, especially on exams. If you are asked to define a pdf/cdf over the entire real ine, then you must get both the support \\(S\\) and “0 otherwise” parts correct.\nYes, you will be integrating functions in this class! While I may ask you do to more involved calculations, eg integration by parts, on homework, I don’t ask these longer calculation-focused questions on exams. Often (but not always) on exams, I’ll ask you to appropriately “set-up” an integral but not actually complete the calculation.\nYou can check integration calculations using technology, but you can’t let technology do all the work. See the AI/tech homework policy on the syllabus.\n\n\n\nSection 6.2 and 7.1.3\nKey terminology to know:\n\ncumulative distribution function (cdf) of a continuous RV\nquantile of a continuous RV\n\nComments:\n\nTake some time to make sure you see how pdf’s and cdf’s are related for continuous random variables.\nTake a look at the cdf example for a discrete RV, but I find cdf most useful for continuous RV. It is essential that you can use/derive cdf for continuous RV, but not as important for discrete (in my class).\nIn 7.1.3, I just want you to review the definition of a quantile and how it relates to a cdf (6.2). You can skim the examples in 7.1.3, but we will formally introduce the normal distribution on another day.\nI’ve seen quantile described either as a percentage or a proportion/probability. E.g. the 50th quantile or the 0.5 quantile. Your book defines it as the former, “50th”, but be comfortable with either description.\n\n\n\nSection 6.4\nKey terminology to know:\n\nuniform RV (know shorthand notation, basic properties)\n\nComments:\n\nYou can just read up to Expectation and Variance on page 240. Review these after day 14’s reading.\nBe comfortable computing probabilities for uniform RV using both a calculus approach and geometric approach. There are pros/cons to each, depending on the problem.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to continuous random variables</span>"
    ]
  },
  {
    "objectID": "intro-continuous-rv.html#day-14",
    "href": "intro-continuous-rv.html#day-14",
    "title": "5  Introduction to continuous random variables",
    "section": "Day 14",
    "text": "Day 14\n\nWhat to read: Read sections 6.3, 6.5, 7.1, 7.2, 7.4\nLearning objectives: These sections will help you\n\ncompute the expected value, variance and sd of a continuous RV\nreview important properties of expected values and variance/sd\nget familiar with some common continous RV types (exponential, normal, gamma, beta)\n\nAfter reading, take reading quiz 12\n\n\nSection 6.3\nKey terminology to know:\n\nexpected value of a continuous RV\nvariance/sd of a continuous RV\n\nComments:\n\nWe’ll cover 6.6-6.8 later this term\n\n\n\nSection 6.5 and 7.2\nKey terminology to know:\n\nexponential RV (know shorthand notation, basic properties)\ngamma RV (know shorthand notation, basic properties)\ngamma function \\(\\Gamma\\)\n\nComments:\n\nExponential and gamma are common models for “waiting times”, eg time until something happens.\nMake sure you recognize the exponential as a special case of the gamma\nWe will cover the connection between these distributions and the Poisson distribution on another day\n\n\n\nSection 7.1\nKey terminology to know:\n\nnormal RV (know shorthand notation, basic properties)\n\nComments:\n\nSkip 7.1.2 (pages 278-282)\n\n\n\nSection 7.4\nKey terminology to know:\n\nbeta RV (know shorthand notation, basic properties)\n\nComments:\n\nThe beta model is very useful for random variables that have a support between 0 and 1.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to continuous random variables</span>"
    ]
  },
  {
    "objectID": "intro-continuous-rv.html#day-15",
    "href": "intro-continuous-rv.html#day-15",
    "title": "5  Introduction to continuous random variables",
    "section": "Day 15",
    "text": "Day 15\n\nWhat to read: Read sections 8.1\nLearning objectives: This section will help you\n\nuse cdf’s to derive the distribution (cdf, then pdf) of a function of a continuous RV\n\nNo reading quiz on section 8.1\n\n\nSection 8.1\nKey terminology to know:\n\ncdf and pdf (make sure these ideas are solid)\n\nComments:\n\nSkim 8.1.1 and skip 8.1.2\nThis section outlines how to derive the pdf of a function of a RV using the cdf method.\nThis method always “works”, though often the mgf method is simpler if the function is linear and the pdf distribution is a common one (eg normal, exponential, etc).\n\n\n\n\n\nWagaman, & Dobrow, A. S. 2021. Probability: With Applications and r. 2nd ed. Wiley.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to continuous random variables</span>"
    ]
  },
  {
    "objectID": "intro-poisson-process.html",
    "href": "intro-poisson-process.html",
    "title": "6  Poisson Process",
    "section": "",
    "text": "Day 16",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Process</span>"
    ]
  },
  {
    "objectID": "intro-poisson-process.html#day-16",
    "href": "intro-poisson-process.html#day-16",
    "title": "6  Poisson Process",
    "section": "",
    "text": "What to read: Read section 7.3 through page 299.\nLearning objectives: These sections will help you\n\nunderstand what a Poisson process is\nsee how “interarrival” or waiting times between Poisson events can be modeled by exponential or gamma distributed random variables\n\nAfter reading, take reading quiz 13\n\n\nSection 7.3\nKey terminology to know:\n\nPoisson process with \\(N_t \\sim Pois(\\lambda t)\\)\nInterarrival times \\(E_k \\sim Exp(\\lambda)\\)\nTime until the \\(nth\\) event \\(S_n \\sim Gamma(n,\\lambda)\\)\n\nComments:\n\nYou can skim/skip the proof on page 296 (up to example 7.15). This proof of the Poisson process model relies on joint pdf which we haven’t covered yet.\nThere is a typo on page 298: The Stationary increments property should state that “For all \\(0 &lt; s,t\\), …” instead of \\(0 &lt; s &lt; t\\)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Process</span>"
    ]
  },
  {
    "objectID": "intro-joint-dist.html",
    "href": "intro-joint-dist.html",
    "title": "7  Introduction to joint distributions",
    "section": "",
    "text": "Day 18",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introduction to joint distributions</span>"
    ]
  },
  {
    "objectID": "intro-joint-dist.html#day-18",
    "href": "intro-joint-dist.html#day-18",
    "title": "7  Introduction to joint distributions",
    "section": "",
    "text": "What to read: Read sections 4.3, 6.6, review Appendix D if you need multivariate integration review\nLearning objectives: These sections will help you\n\nunderstand what a joint distribution (pdf/pmf) is\nunderstand what a marginal distribution (pdf/pmf) is\ncompute a marginal pdf/pmf from a joint pdf/pmf\ncompute probabilities from a joint pdf/pmf\n\nAfter reading, take reading quiz 14\n\n\nSections 4.3 and 6.6\nKey terminology to know:\n\njoint pmf (two discrete RV) and joint pdf (two continuous RV)\nmarginal distribution (pmf or pdf)\ncontinuous joint cdf\ncontinuous bivariate pdf\n\nComments:\n\nYou can skip over the expectations on page 139 (equation 4.3) and 255 for now - we’ll cover this idea Friday.\nComputing probabilities from a joint pdf requires calculation of a double integral. As in single random variable integration, setting up the problem with the correct limits of integration is the key step here. Draw a picture of the event (region) that you want to find the probability of and intersect it with the support set for your pdf. It is this region that determines your limits!\nMake sure you review Appendix D if you are rusty with double integrals.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introduction to joint distributions</span>"
    ]
  },
  {
    "objectID": "intro-joint-dist.html#day-19",
    "href": "intro-joint-dist.html#day-19",
    "title": "7  Introduction to joint distributions",
    "section": "Day 19",
    "text": "Day 19\n\nWhat to read: Read section 6.7, review independence from 4.4\nLearning objectives: These sections will help you\n\nunderstand what independence for two (or more) RV means\nhow to prove independence OR how to use independence to construct joint pdf/pmf\n\nAfter reading, take reading quiz 15\n\n\nSections 4.4 and 6.7\nKey terminology to know:\n\nindependent continuous RV\nindependent discrete RV\n\nComments:\n\nYou can skim 6.7.1 on the accept-reject method.\nThe assumption of independence between two RV makes the derivation of the joint pdf/pmf very easy since it is just the product of the two (marginal) pdf/pmf.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introduction to joint distributions</span>"
    ]
  },
  {
    "objectID": "intro-joint-dist.html#day-20",
    "href": "intro-joint-dist.html#day-20",
    "title": "7  Introduction to joint distributions",
    "section": "Day 20",
    "text": "Day 20\n\nWhat to read: Read expectation definitions on pages 139 and 255 and sections 4.7, 6.8, 9.6\nLearning objectives: These sections will help you\n\ncompute the expected value of a function of two discrete or continuous RV\nunderstand how covariance and correlation are used to measure the linear dependence between two RV\ncompute the covariance and correlation between two RV\ncompute the variance of a linear combination of two RV when they are not independent\nsee an example of a bivariate distribution with a parameter that measures correlation\n\nAfter reading, take reading quiz 16\n\n\nSections 4.7, 6.8, and 9.6 and pages 139, 255\nKey terminology to know:\n\nexpected value of a function of two RV\ncovariance\ncorrelation\ngeneral formula for the variance of a sum of random variables\nbivariate normal model\n\nComments:\n\nTake a look at section 9.6 through page 391 to see an example of a joint pdf with a parameter that measures correlation.\n\n\n\n\n\nWagaman, & Dobrow, A. S. 2021. Probability: With Applications and r. 2nd ed. Wiley.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introduction to joint distributions</span>"
    ]
  },
  {
    "objectID": "more-joint-dist.html",
    "href": "more-joint-dist.html",
    "title": "8  More with joint and conditional distributions",
    "section": "",
    "text": "Day 21",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>More with joint and conditional distributions</span>"
    ]
  },
  {
    "objectID": "more-joint-dist.html#day-21",
    "href": "more-joint-dist.html#day-21",
    "title": "8  More with joint and conditional distributions",
    "section": "",
    "text": "What to read: Read sections 8.2, 8.3, 8.4\nLearning objectives: These sections will help you\n\nderive the pdf of a minimum or maximum\nderive the pmf/pdf of a sum of two independent RV using a convolution of functions\n\nAfter reading, take reading quiz 17\n\n\nSections 8.2\nKey terminology to know:\n\norder statistics\ninequalities for mins and maxs\n\nComments:\n\nFocus on material involving the min \\(X_{(1)}\\) and max \\(X_{(n)}\\) order statistics.\nYou can skim the proof of the beta distribution for general \\(X_{(k)}\\) for \\(1 &lt; k &lt; n\\) when your sample is iid uniform. (pages 333-334)\n\n\n\nSections 8.3\nKey terminology to know:\n\nconvolution of two functions\n\nComments:\n\nThe convolution method of finding the pdf of \\(X+Y\\) is an example of a CDF transformation method (i.e. find the CDF then differentiate to find PDF)\nReview section 4.4.1 equation 4.7 for review of the analogous discrete version of 8.3.\n\n\n\nSections 8.4\nComments:\n\nThis section reviews both how to use geometry to compute probabilities from uniform pdfs and use of the CDF method to find PDF for a function of two RV.\nYou can skim 8.23 (Buffon’s needle problem is fun but you won’t necessarily see trig calculations in hw/exam problems!)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>More with joint and conditional distributions</span>"
    ]
  },
  {
    "objectID": "more-joint-dist.html#day-22",
    "href": "more-joint-dist.html#day-22",
    "title": "8  More with joint and conditional distributions",
    "section": "Day 22",
    "text": "Day 22\n\nWhat to read: Read sections 4.8, 9.1, 9.2\nLearning objectives: These sections will help you\n\nderive conditional pmf/pdf from joint and marginal models\napply Bayes formula to conditional pmf/pdf\n\nAfter reading, take reading quiz 18\n\n\nSections 4.3, 9.1, and 9.2\nKey terminology to know:\n\nconditional pmf\nconditional pdf\nBayes formula for pdf\n\nComments:\n\nWe will cover expected value in 4.8.1 on Day 23.\nTake care when deriving conditional pmf/pdf. E.g the pdf \\(f(y \\mid x)\\) of \\(Y \\mid X=x\\) is a function of \\(y\\) and \\(x\\) is a constant.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>More with joint and conditional distributions</span>"
    ]
  },
  {
    "objectID": "more-joint-dist.html#day-23",
    "href": "more-joint-dist.html#day-23",
    "title": "8  More with joint and conditional distributions",
    "section": "Day 23",
    "text": "Day 23\n\nWhat to read: Read sections 9.3, 9.5\nLearning objectives: These sections will help you\n\nCompute a conditional pmf/pdf’s expected value and variance given a fixed value of the conditioning variable\nCompute a marginal expected value or variance from a RV’s conditional distribution\n\nAfter reading, take reading quiz 19\n\n\nSections 9.3 and 9.5\nKey terminology to know:\n\nConditional expected value of \\(Y\\) given \\(X=x\\): \\(E(Y \\mid X=x)\\) (similar for flipping the roles of \\(X\\) and \\(Y\\))\nConditional variance of \\(Y\\) given \\(X=x\\): \\(V(Y \\mid X=x)\\) (similar for flipping the roles of \\(X\\) and \\(Y\\))\nLOTUS for conditional distributions\nConditional expected value of \\(Y\\) given \\(X\\): \\(E(Y \\mid X)\\) (similar for flipping the roles of \\(X\\) and \\(Y\\))\nConditional variance of \\(Y\\) given \\(X\\): \\(V(Y \\mid X)\\) (similar for flipping the roles of \\(X\\) and \\(Y\\))\nLaw of total expectation\nLaw of total variance\n\nComments:\n\nFor these sections, we are framing the conditional relation as “\\(Y\\) given \\(X\\)”. The same rules/def/ideas apply if we flip the roles of \\(Y\\) and \\(X\\), so don’t get stuck on a particular formula - try to see how things would generalize to any RV. E.g. examples 9.13 and 9.14 switch up notation.\nFor these sections, we often frame the known information/models as being given the distribution (marginally) of \\(X\\) and the conditional distribution of \\(Y\\) given \\(X=x\\) (or \\(X\\)). As already mentioned, we could flip the roles of the RVs and have the same general rules apply.\nI know these sections can get confusing since we are talking about very similar things with similar notation. One important idea, though, is whether a value (exp/var) is fixed (but maybe unknown, in formula form) or random.\n\n\\(E(Y \\mid X=x)\\) assumes that we know a value of \\(X=x\\). The final answer may be a function of \\(x\\), but \\(x\\) is a fixed (not random) value. Like in Ex 9.12, \\(E(Y \\mid X=0.6) = (0.6)/2=0.3\\) is the expected value of Miguel’s number if Riley picks \\(X=0.6\\).\n\\(E(Y \\mid X) = g(X)\\) keeps \\(X\\) random. Why do this? We might want to know how \\(E(Y \\mid X) = g(X)\\) behaves over all possible, random, values of \\(X\\). Like in Ex 9.12, \\(E(Y \\mid X) = X/2\\) tells us that the random variable \\(X/2\\) models the expected value of Miguel’s number as a function of the random value \\(X\\) of Riley’s pick.\n\nThe law of total expectation tells us the “average” value of \\(E(Y \\mid X)\\) over all values of \\(X\\) (“averaged” over the pdf/pmf of \\(X\\)). It is a way to get the unconditional expectation of \\(Y\\) without having to compute the marginal distribution of \\(Y\\).\n\ne.g. in Ex 9.12, \\(E(Y \\mid X) = X/2\\) tells us the expected value of Miguel’s number as a function of the random value \\(X\\). If \\(X \\sim Unif(0,1)\\), then \\(E(X) = 0.5\\) and the unconditional expectation for Miguel’s number is \\(E(Y) = E_x(E(Y \\mid X)) = E_x(X/2) = (0.5)/2 = 0.25\\). As a gut check, we should expect the expectation for Miguel to be lower than Riley because Riley’s number always dictates the upper bound on Miguel’s number.\n\nThe law of total variance (LOTV) is similar in spirit to the law of total expectation, that we want to understand the variance of \\(Y\\) unconditionally when what we are given is the conditional variance. But, the equation for the LOTV is more complex because the variance term is more complex: it involves taking an expectation of squared deviation of the RV from its expectation. The LOTV is computed with two parts:\n\n\\(E_x(V(Y \\mid X))\\): “average” the conditional variance (RV) \\(V(Y\\mid X)\\) over all values of \\(X\\) (“averaged” over the pdf/pmf of \\(X\\)).\n\\(V_x(E(Y \\mid X))\\): measure the variation of the conditional expected value (RV) \\(E(Y\\mid X)\\) over all values of \\(X\\) (variation with respect to the pdf/pmf of \\(X\\)).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>More with joint and conditional distributions</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Wagaman, & Dobrow, A. S. 2021. Probability: With Applications\nand r. 2nd ed. Wiley.",
    "crumbs": [
      "References"
    ]
  }
]