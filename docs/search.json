[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "math-240-notes",
    "section": "",
    "text": "Math 240 Probability\nThis is a reading guide resource for students in my Math 240 Probability class taught at Carleton College (Northfield, MN). Our textbook is Wagaman (2021). You can find this book online in our library.\n\n\n\n\nWagaman, & Dobrow, A. S. 2021. Probability: With Applications and r. 2nd ed. Wiley.",
    "crumbs": [
      "Math 240 Probability"
    ]
  },
  {
    "objectID": "first-principles.html",
    "href": "first-principles.html",
    "title": "1  First principles of probability",
    "section": "",
    "text": "Day 1",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>First principles of probability</span>"
    ]
  },
  {
    "objectID": "first-principles.html#day-1",
    "href": "first-principles.html#day-1",
    "title": "1  First principles of probability",
    "section": "",
    "text": "What to read: Read sections 1.1, 1.2, 1.3, 1.4, and 1.8 to see the generalization of property #3.\nLearning objectives: These sections will help you\n\ndefine basic probability and set theory terminology\ndefine fundamental properties of probability\n\n\n\nSection 1.1\nKey terminology to know:\n\nSample space \\(\\Omega\\)\nOutcome \\(\\omega\\): this can also be called an element\nEvent \\(A\\), \\(B\\), …\n\nComments:\nThe sample space for a random experiment is the list of all possible outcomes. To define a sample space, start by thinking about how to define a couple individual outcomes and then generalize this to all outcomes. If there are a large or infinite number of outcomes, then you can use a “…” to show that a pattern will continue (like Examples 1.3 and 1.4).\nThere may not be a unique way to define a sample space and outcomes for a random experiment. For example, one may chose to define the sample space for Example 1.3 as just the number of votes for Yolanda \\[\\Omega = \\{ 0, 1, 2, \\dotsc, 999, 1000\\}\\]. But all the outcomes in a sample space must define unique possibilities for a random experiment (i.e. they are mutually exclusive, section 1.4).\n“Complex” random experiments are often composed of simpler experiments. Example 1.2 is an example of this as we define one outcome for two dice rolls as the joint outcome of two individual die rolls. Similar for the sample space for three coin flips. In scenarios where the individual simpler experiments have equally likely outcomes, the outcomes in the more complex sample space (e.g. two dice rolls, three coin flips) are also equally likely outcomes.\n\n\nSection 1.2-1.3\nKey ideas to know:\n\nrelative frequency interpretation of probability\nprobability function and its essential properties\n\nComments:\nMake sure you can put the probability function properties into words: (1) means probabilities can’t be negative, (2) means something in the sample space has to happen with probability 1 and (3) means the probability of an event is just the sum of the probabilities of outcomes that make up that event.\n\n\nSection 1.4 + 1.8\nKey set theory ideas to know\n\ncomplement \\(A^c\\) (not \\(A\\))\nunion \\(A \\cup B\\) (at least one \\(A\\) or \\(B\\) or both)\nintersection \\(A \\cap B = AB\\) (both \\(A\\) and \\(B\\))\n\\((AB)^c = A^c \\cup B^c\\) (at most one)\n\\((A \\cup B)^c = A^cB^c\\) (neither)\n\\(AB^c\\) (\\(A\\) but not \\(B\\))\nsubset \\(\\subseteq\\)\nmutually exclusive/disjoint events\nVenn diagram\nempty set \\(\\emptyset\\)\n\nComments:\nThe first six ideas create a new event out of one or more events (think addition, subtraction, etc). Subset, mutually exclusive and Venn diagrams tells us relational information about events (think less than, etc). The empty set is a set that has no outcomes (think zero).\nKey probability properties to know\n\nAddition rule for mutually exclusive events (only add probability of events when they are mutually exclusive)\nGeneral addition rule (events do not need to be mutually exclusive)\nComplement rule\n\nComments:\nThe addition rule properties are used to find the probability of a union of two or more events. When events are mutually exclusive, we just add the individual event probabilities. Make sure that you assess whether events are mutually exclusive before simply adding their probabilities.\nWhen events are not mutually exclusive, you start by adding event probabilities but then you need to subtract out the probability of the overlap (intersection) between events. The inclusion/exclusion rule is an extension of property (3) (eq. 1.3).\nThe complement rule along with the addition rule is useful for computing the probability of neither \\(A\\) nor \\(B\\): \\[\nP(A^c B^c) = 1 - P(A \\cap B)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>First principles of probability</span>"
    ]
  },
  {
    "objectID": "first-principles.html#day-2",
    "href": "first-principles.html#day-2",
    "title": "1  First principles of probability",
    "section": "Day 2",
    "text": "Day 2\n\nWhat to read: Read sections 1.5 and 1.6\nLearning objectives: These sections will help you\n\nuse the multiplication principle to count the number of outcomes in a sample space or event\ncompute event probabilities using counting when outcomes are equally likely\ndefine and count permutations\n\nAfter reading, take reading quiz 1\n\n\nSection 1.5\nKey idea to know:\n\nequally like outcomes\n\nComments:\nOur definition of the probability function Section 1.3 means that the probability of any event \\(A\\) is equal to the number of outcomes in \\(A\\) divided by the total number of outcomes when all outcomes are equally likely.\n\n\nSection 1.6\nKey ideas to know:\n\nmultiplication principle\npermutation\ncounting the number of permutations of \\(n\\) unique/distinct objects\ncounting the number of permutations of size \\(k\\) from \\(n\\) unique/distinct objects\nsampling with vs without replacement\n\nComments:\nThe outcomes counted by the multiplication principle describe a specific ordering, or arrangement, of a random experiment. For example 1.13, the outcomes in the sample space are found by fixing the exam (eg exams 1-4) and randomly assigning one of five grades to each exam. There are \\(5\\times5\\times5\\times5 = 5^4\\) such outcomes in the sample space. The complement of the event of interest is getting no A’s and we must describe outcomes in this set the same way that we described them in the sample space (eg assigning one of four non-A grades to each exam). There are \\(4^4\\) such ways to assign a non-A grade to each exam.\nPermutations are always ordered arrangements of unique/distinct objects or individual outcomes.\nExample 1.14 shows a common technique in counting problems. One outcome describes a specific (unique) arrangement of 15 books (eg positions 1-5 are top shelf, 6-10 middle, and 11-15 bottom). There are 15! such arrangements in the sample space. The event of interest, all math books on the bottom, uses both permutation counting and the multiplication principle. Permutations counts the number of ways to arrange math books (5!) and novels (10!). Each unique arrangement of math books can be combined with each unique arrangement of novels. Hence the multiplication principle is used to count the number of ways to get 10 novels on the top and middle shelves and 5 math books on the bottom: \\(10! \\times 5!\\).\nOne twist to problem 1.14: suppose the event of interest was simply that the 5 math books were on the same shelf (ie they could be on the top, middle or bottom shelves). Each of these three options, \\(A_{top}, A_{middle}, A_{bottom}\\) for math book placement has \\(10! \\times 5!\\) ways to arrange the books and each of these shelf positions \\(A_{i}\\) is mutually exclusive. Hence the probability that the 5 math books are on the same shelf is found using the addition rule for mutually exclusive events: \\[\nP(A_{top} \\cup A_{middle} \\cup A_{bottom}) = P(A_{top}) + P(A_{middle}) +  P(A_{bottom}) = 3 \\times \\dfrac{10! \\times 5!}{15!}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>First principles of probability</span>"
    ]
  },
  {
    "objectID": "first-principles.html#day-3",
    "href": "first-principles.html#day-3",
    "title": "1  First principles of probability",
    "section": "Day 3",
    "text": "Day 3\n\nWhat to read: Read sections 1.7\nLearning objectives: These sections will help you\n\ndefine and count combinations using the binomial coefficient\nuse the binomial coefficient to count permutations of two types of objects (a binary sequence)\ndistinguish between a permutation and a combination\n\nAfter reading, take reading quiz 2\n\n\nSection 1.7\nKey ideas to know:\n\ncombination\ncorrespondence between a binary sequence/list and an unordered subset/sample of size \\(k\\) from \\(n\\) unique objects\nbinomial coefficient\n\nComments:\nWe will be considering counting problems where outcomes are either ordered and unordered. Make sure that your strategy for solving a problem is consistent when counting sample space and event outcomes (eg don’t use an ordered strategy for one and an unordered strategy for the other).\nWhile you need to describe outcomes in an event and sample space of interest in the same manner, you don’t need to use the same counting method to count outcomes in each. e.g. Example 1.26 uses the multiplication principle to count all possible ways to flip a coin 20 times while the binomial coefficient is used to count how many of these outcomes contain example 10 H and 10 T.\nThe binomial coefficient, which counts both the number of unordered subsets of unique objects and the number of binary sequences, can be generlized to a multinomial coefficient. Example 1.15(ii) involves picking 4 subsets of 13 cards from a deck of 52: \\(\\frac{52!}{13!13!13!13!}\\). Example 1.27(ii) also uses a multinomial coefficient in the numerator: \\(\\frac{20!}{4!5!3!8!}\\) counts the number of ways to arrange 4 As, 5 Gs, 3 Ts, and 8 Cs.\nDon’t worry about the binomial theorem (and its proof) for now.\n\n\n\n\nWagaman, & Dobrow, A. S. 2021. Probability: With Applications and r. 2nd ed. Wiley.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>First principles of probability</span>"
    ]
  },
  {
    "objectID": "thinking-conditionally.html",
    "href": "thinking-conditionally.html",
    "title": "2  Thinking conditionally",
    "section": "",
    "text": "Day 4",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Thinking conditionally</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Wagaman, & Dobrow, A. S. 2021. Probability: With Applications\nand r. 2nd ed. Wiley.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "thinking-conditionally.html#day-4",
    "href": "thinking-conditionally.html#day-4",
    "title": "2  Thinking conditionally",
    "section": "",
    "text": "What to read: Read sections 2.1, 2.2, 2.3\nLearning objectives: These sections will help you\n\nhow to conceptualize and compute a conditional probability\ngeneral multiplication rule to compute the probabilities of intersections\nuse tree diagrams to organize conditional information and compute probabilities\n\nAfter reading, take reading quiz 3\n\n\nSection 2.1 and 2.2\nKey terminology to know:\n\nconditional probability function and its essential properties\n\nComments:\nDon’t get bogged down in the notation choice used to define a conditional probability, \\(P(A \\mid B)\\). The big idea is that to compute a conditional probability we compute the ratio of the intersection probability (chance that both events occur) relative to the probability of the event we are conditioning on (ie the event that has occurred).\nDon’t worry about the simulation code in example 2.3.\nThe conceptual idea in 2.2 is most important, that a conditional probability function \\(P( \\cdot \\mid B)\\) should have the same properties as an unconditional probability \\(P(\\cdot)\\). The only difference is that the sample space for the conditional probability is restricted to only outcomes that agree with the conditional information.\n\n\nSection 2.3\nKey terminology to know:\n\ngeneral multiplication rule for two or more events\ntree diagram\n\nComments:\nTree diagrams are a useful visual tool for organizing information that is conditional or sequential in nature. Venn diagrams are not useful for organizing such information.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Thinking conditionally</span>"
    ]
  },
  {
    "objectID": "thinking-conditionally.html#day-5",
    "href": "thinking-conditionally.html#day-5",
    "title": "2  Thinking conditionally",
    "section": "Day 5",
    "text": "Day 5\n\nWhat to read: Read sections 2.4 and 2.5\nLearning objectives: These sections will help you\n\nuse the law of total probability to compute an unconditional probability from conditional information\nuse Bayes rule to compute a “flipped/inverted” conditional probability\n\nAfter reading, take reading quiz 4\n\n\nSection 2.4\nKey terminology to know:\n\nsample space partition\nlaw of total probability (LoTP)\n\nComments:\nRecognize that the LoTP uses both the multiplication rule (to compute intersections) and the addition rule for mutually exclusive events.\n\n\nSection 2.5\nKey terminology to know:\n\nBayes formula/rule\ntree diagram\n\nComments:\nBayes formula is useful when we want to flip the direction of a conditional probability, eg. we want \\(P(B \\mid A)\\) but we are given \\(P(A \\mid B)\\) along with unconditional info about \\(B\\). But the formula didn’t appear from nothing, it is based on the original definition of a conditional probability from 2.1: the numerator is the multiplication rule and the denominator is the LoTP.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Thinking conditionally</span>"
    ]
  },
  {
    "objectID": "thinking-conditionally.html#day-6",
    "href": "thinking-conditionally.html#day-6",
    "title": "2  Thinking conditionally",
    "section": "Day 6",
    "text": "Day 6\n\nWhat to read: Read sections 2.6\nLearning objectives: These sections will help you\n\ndetermine whether events are independent or dependent\ncompute intersection probabilities if events are independent\n\nAfter reading, take reading quiz 5\n\n\nSection 2.6\nKey terminology to know:\n\nindependent and dependent events\nmutual independence\nmultiplication rule for independent events\n\nComments:\nIndependence is proved (or disproved) by thinking conditionally: if the occurrence of \\(B\\) doesn’t affect the probability of \\(A\\), then these events are independent.\nIf we know events are independent, then we can multiply unconditional probabilities to compute intersections. A common error is that I see is when the multiplication rule for independent events is used without first checking the essential assumption of independence.\nDon’t worry about \\(A\\) before \\(B\\) results (ie they are interesting but not a general rule you need to know).\n\n\n\n\nWagaman, & Dobrow, A. S. 2021. Probability: With Applications and r. 2nd ed. Wiley.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Thinking conditionally</span>"
    ]
  },
  {
    "objectID": "intro-discrete-rv.html",
    "href": "intro-discrete-rv.html",
    "title": "3  Introduction to discrete random variables",
    "section": "",
    "text": "Day 7",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to discrete random variables</span>"
    ]
  },
  {
    "objectID": "intro-discrete-rv.html#day-7",
    "href": "intro-discrete-rv.html#day-7",
    "title": "3  Introduction to discrete random variables",
    "section": "",
    "text": "What to read: Read sections 3.1, 3.2, 3.3, 3.4, plus the pmf definition on page 126\nLearning objectives: These sections will help you\n\nunderstand what a “random variable” (RV) is\ndefine a probability mass function and support set for a discrete RV\nunderstand whether discrete RV are independent\nget familiar with some common discrete RV types (uniform, Bernoulli, binomial, Poisson)\n\nAfter reading, take reading quiz 6\n\n\nSection 3.1 and page 126\nKey terminology to know:\n\nrandom variable\ndiscrete random variable\nprobability mass function (pmf) of a RV\nthe (support) set \\(S\\) of a RV\nuniform RV (know shorthand notation, pmf and support set)\n\nComments:\nPay special attention to the notation used for random variables (RV). Uppercase letters (typically at the end of the English alphabet) are used to denote the RV (which is random and doesn’t have a fixed value) while lower case are used to denote a fixed numeric value (which is fixed even though there may not be a value specified).\nThe “distribution” of a random variable describes the probability structure of the RV, so think pmf if you are asked to describe a distribution. (ie what values of the RV are most likely, which ones are less likely, etc) You can also describe a distribution of a RV by name if it has a common pmf (eg “The distribution of \\(X\\) is discrete uniform.”)\nThe subsection “Random variables as function” explains how a RV \\(X(\\cdot)\\) takes in one or more outcomes \\(\\omega\\) from the sample space of an experiment and outputs a numeric value. This is our formal definition of a RV but we typically won’t be using the \\(X(\\omega)\\) notation for a RV. Instead we will just refer to RV as \\(X\\), \\(Y\\), etc. But keep this underlying connection with the sample space in mind as the term progresses (especially for discrete RV).\nThe uniform random variable box on page 96 is an example of a probability mass function (pmf) and support set \\(S\\). Even though pmf aren’t formally defined until ch. 4, I find it useful to use that language at the start of discrete RV discussions.\n\n\nSection 3.2\nKey terminology to know:\n\nindependent discrete random variables\n\nComments:\nWe can use either Equations 3.1 or 3.2 to define two independent discrete RV. The general definition of independent random variables on page 98 extends beyond discrete RV to continuous RV (which we will cover soon). Skim this idea but our main focus right now is discrete RV.\n\n\nSection 3.3 and 3.4\nKey terminology to know:\n\nBernoulli RV (know shorthand notation, what it counts, pmf and support set)\nIndependent and identically distributed (i.i.d.)\nBinomial RV (know shorthand notation, what it counts, pmf and support set)\n\nComments:\nBernoulli and binomial RV are extremely common types of RV so make sure to carefully review these sections.\nYour book describes a binomial RV as the sum of an [i.i.d.] Bernoulli “sequence” of length \\(n\\). Another common way to describe this is the use the phrasing “trials” instead of “sequence”: a binomial RV is the sum of \\(n\\) i.i.d. Bernoulli trials.\nThe R code on pages 102 and 104 will be talked about on day 8.\nSkim Example 3.14 but we will focus on solving problems involving two RV later on this term.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to discrete random variables</span>"
    ]
  },
  {
    "objectID": "intro-discrete-rv.html#day-8",
    "href": "intro-discrete-rv.html#day-8",
    "title": "3  Introduction to discrete random variables",
    "section": "Day 8",
    "text": "Day 8\n\nWhat to read: Read sections 3.5\nLearning objectives: These sections will help you\n\nget familiar with the Poisson distribution\nreview or get introduced to infinite series\n\nAfter reading, take reading quiz 7\n\n\nSection 3.5\nKey terminology to know:\n\nPoisson RV (know shorthand notation, what it counts, pmf and support set)\n\nComments:\nA Poisson RV is another RV that counts “things”, make sure you can distinguish settings where we should be modeling a count RV as a Poisson RV vs. a binomial RV (vs. something else).\nSeries are a Calc BC or Math 210 topic that not all of you have seen. If you haven’t had prior exposure to these ideas please stop by drop-in hours (or make an appointment) if you have questions! Appendix C at the end of your book reviews some useful math/calc facts, including some common series. You can use these facts without deriving them from scratch.\nSkim 3.5.1 and 3.5.2. Time permitting, I’ll cover the proof connecting the binomial and Poisson distributions from 3.5.2 class (it’s fun!) but it isn’t essential course material.\n\n\n\n\nWagaman, & Dobrow, A. S. 2021. Probability: With Applications and r. 2nd ed. Wiley.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to discrete random variables</span>"
    ]
  }
]